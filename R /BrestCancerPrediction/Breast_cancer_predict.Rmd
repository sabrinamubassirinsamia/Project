---
title: "Brest_cancer_prediction"
author: "Sabrina Mobassirin"
date: "2023-09-23"
output: pdf_document
---

```{r setup, include=FALSE}
library(tidyverse) #For tidying the data
library(skimr) #It is designed to provide summary statistics about variables in data frames
library(ggplot2) #For plotting
library(RColorBrewer) #For aesthetics
library(tidymodels) #For splitting the data and training
library(caret) #For machine learning
library(party) #The core of the package is ctree()
library(yardstick) #For plotting the confusion matrix

```


```{r}
df <- read.csv("/Users/sabrinamobassirin/Downloads/Fall23/Stat5301_Applied Regression/Project/Brest_Cancer_prediction/breastcancer.csv")

```

```{r}
dim(df)

names(df)

```

```{r}
str(df)

summary(df)
```

```{r}
any(is.na(df))

colnames(df)

colSums(is.na(df))
```
```{r}

# Replacing the values of these columns by the mean
df$radius_mean[is.na(df$radius_mean)] <- mean(df$radius_mean, na.rm = TRUE)
df$concave.points_mean[is.na(df$concave.points_mean)] <- mean(df$concave.points_mean,na.rm = TRUE)
df$smoothness_se[is.na(df$smoothness_se)] <- mean(df$smoothness_se, na.rm = TRUE)
df$texture_worst[is.na(df$texture_worst)] <- mean(df$texture_worst, na.rm = TRUE)
df$symmetry_worst[is.na(df$symmetry_worst)] <- mean(df$symmetry_worst, na.rm = TRUE)
# checking again if there is any NA values in the numeric columns
colSums(is.na(df))
                     
```

```{r}
# the only columns that is character is "diagnosis"
# this is a function to find the mode in a column
calc_mode <- function(x)
  {
  # List the distinct / unique values
  distinct_values <- unique(x)
  # Count the occurrence of each distinct value
  distinct_tabulate <- tabulate(match(x, distinct_values))
  # Return the value with the highest occurrence
  distinct_values[which.max(distinct_tabulate)]
  }
# replacing the NA values by the mode
df <- df %>% 
  mutate(diagnosis = if_else(is.na(diagnosis), 
                         calc_mode(diagnosis), 
                         diagnosis))
# checking again for NA values in the data.
any(is.na(df)) #Should Be FALSE


```
Q1- How to predict a breast tumor is malignant or benign? (Classification problem)
Q2- How to predict the mean of the lobes radius of breast cancer tumor? (Regression Problem)
 Making a copy of the Data set for classification manipulation
 
```{r}
df_c <-df
df_c
```

EDAs

```{r}
skim_without_charts(df_c)

```


```{r}
df_c %>% count(diagnosis)

# setting diagnosis column to factor for plotting and modeling
df_c$diagnosis <- as.factor(df_c$diagnosis)
# plotting the bar plot
ggplot(df_c, aes(x=diagnosis, fill= diagnosis)) +
geom_bar(stat="count") +
theme_classic() +
scale_y_continuous(breaks = seq(0, 400, by = 25)) +
labs(title="Distribution of Diagnosis")


fig2 <- df_c[c("radius_mean", "diagnosis")]
# plotting the box plot
ggplot(fig2, aes(diagnosis, radius_mean, fill = diagnosis)) + 
  geom_boxplot()+
  labs(col="Type of The Tumor") + ylab("lobes radius mean") +
labs(title="Distribution of diagnosis")+
  # changing the color of the boxplots
  scale_fill_manual(values = c( "dodgerblue1","red3")) 
```
```{r}

ggplot(df_c, aes(radius_mean, concavity_mean)) +
  geom_point(aes(color = diagnosis)) +
  labs(title = "Radious mean Vs Concavity mean",
       y = "Mean of Concavity", x = "Radius of Lobes",
       col="Type of The Tumor")+
   scale_colour_manual(labels = c("Benign", "Malignant"),
                       values = c("dodgerblue1","red2")) +
  theme_bw()

```
```{r}
# Picking the columns that are highly correlated with the mean of lobes radius
df_R <- df[c("perimeter_mean", "area_mean" , "concave.points_mean", "radius_worst", 
       "radius_worst", "perimeter_worst", "area_worst", "radius_mean" )]
cor(df_R)[,8]

```


```{r}

ggplot(df_R, aes(radius_mean, area_mean))+ 
  geom_point(aes(alpha = 0.1))+ geom_smooth(method = "lm") + 
  labs(title = "The mean of lobes radius Vs the mean of the lobes area",
       y = "The mean of lobes areas", x = "The mean of lobes radius") +theme_bw()


```


```{r}

ggplot(df_R, aes(radius_mean, perimeter_mean))+ 
  geom_point(aes(alpha = 0.1))+ geom_smooth(method = "lm") + 
  labs(title = "The mean of lobes radius Vs the mean of the lobes perimeter", 
       y = "The mean of lobes perimeter", x = "The mean of lobes radius") +theme_bw()

```


```{r}
#Splitting The Data to Training and Testing Sets
split=0.80 # define an 80%/20% train/test split of the dataset
trainIndex <- createDataPartition(df_R$radius_mean, p=split, list=FALSE)
data_train_R <- df_R[ trainIndex,]
data_test_R <- df_R[-trainIndex,]
#Training The Multiple Linear Regression Model
model3 <- lm(radius_mean ~ perimeter_mean+area_mean+concave.points_mean+radius_worst+radius_worst+
               perimeter_worst+area_worst,data = data_train_R)
#Examining The Coefficient Table
summary(model3)$coefficient
                        

```

```{r}
#Using The Model on The Test Data to Predict The Radius Mean
prediction_R = predict(model3, newdata =data_test_R, interval = "prediction")
head(prediction_R) #Exploring the head of our prediction table
        
```


```{r}
#Scatter Plot for The Actual Values Vs the Predicted Values for Radius Mean
# binding the predicted values with the actual ones
act_pred <- as.data.frame(cbind(data_test_R$radius_mean,prediction_R )) 
# taking only the predicted and actual values without the upper and lower boundaries
act_pred <- act_pred[,1:2]
#renaming the columns
act_pred <- act_pred %>% rename( Actual= V1, predicted= fit )
#assigning row names to Null to get rid of the unorganized index
row.names(act_pred) <- NULL
head(act_pred)
  
####
ggplot(act_pred, aes(Actual, predicted)) +
  geom_point(alpha = 0.4) + labs(title = "Predicted Values Vs Actual Values For Radius Mean"
                      , x = "Actual Values of The Test Data",  "Predicted Values of The Test Data")+ theme_gray()


```

```{r}
#Checking The Accuarcy Using The Residual Standard Error (RSE), or Sigma:
# The error rate can be estimated by dividing the RSE by the mean outcome variable:
# the smaller the error the more accurate the model is.
sigma(model3)/mean(data_test_R$radius_mean)


```
Data Science and Statistics are powerful tools that can be used to predict disasters before happening. Breast cancer is a hideous disease, which has a strong negative impact onsociety. In my project, i made a multiple linear regression statistical model that predict the mean of the lobes radius based on seven parameters with an RSE value of 0.06~0.07.